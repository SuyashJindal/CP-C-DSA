ğ—¼ğ—»-ğ—¦ğ˜ğ—®ğ˜ğ—¶ğ—¼ğ—»ğ—®ğ—¿ğ˜† ğ—§ğ—¶ğ—ºğ—² ğ—¦ğ—²ğ—¿ğ—¶ğ—²ğ˜€
A non-stationary series has changing patterns over time.

ğŸ”¹ ğ—ğ—²ğ˜† ğ—³ğ—²ğ—®ğ˜ğ˜‚ğ—¿ğ—²ğ˜€:
â†³ Shocks or structural breaks
â†³ Mean & Variance are changing
â†³ Presence of trend & Seasonality

ğŸ”¹ ğ—˜ğ˜…ğ—®ğ—ºğ—½ğ—¹ğ—²ğ˜€:
â†³ Stock prices
â†³ Monthly revenue
â†³ Daily website traffic with weekly cycles

Most of the time series in the business world are non-stationary.

ğŸ”„ ğ—›ğ—¼ğ˜„ ğ˜ğ—¼ ğ—°ğ—¼ğ—»ğ˜ƒğ—²ğ—¿ğ˜ ğ—»ğ—¼ğ—»-ğ˜€ğ˜ğ—®ğ˜ğ—¶ğ—¼ğ—»ğ—®ğ—¿ğ˜† â†’ ğ˜€ğ˜ğ—®ğ˜ğ—¶ğ—¼ğ—»ğ—®ğ—¿ğ˜†
âœ… ğ——ğ—¶ğ—³ğ—³ğ—²ğ—¿ğ—²ğ—»ğ—°ğ—¶ğ—»ğ—´
Subtract the previous value. Removes trend.

âœ… ğ——ğ—²ğ˜€ğ—²ğ—®ğ˜€ğ—¼ğ—»ğ—®ğ—¹ğ—¶ğ˜‡ğ—¶ğ—»ğ—´
Estimate the seasonal component and subtract it.

âœ… ğ—Ÿğ—¼ğ—´ / ğ—£ğ—¼ğ˜„ğ—²ğ—¿ ğ˜ğ—¿ğ—®ğ—»ğ˜€ğ—³ğ—¼ğ—¿ğ—ºğ˜€
Use when variance increases with level.
///////////



 Tree-Based Models (Better Generalization, Faster Prediction)
LightGBM

âœ… Very fast & memory-efficient

âœ… Handles missing values natively

âœ… Excellent for tabular data like options IV

ğŸ”§ Tune num_leaves, max_depth, learning_rate, n_estimators

XGBoost

Similar to LightGBM, more robust for small datasets

Performs well with high variance targets like IVs

CatBoost

âœ… Categorical handling without encoding

âœ… Robust with fewer hyperparameters

Great for real-world noisy data

ğŸ§  Neural Networks (Nonlinear Patterns, Feature Interactions)
MLPRegressor (from sklearn or PyTorch/TensorFlow)

Flexible architecture for non-linear mapping

Useful when you have many engineered features

ğŸ”§ Needs proper scaling and regularization (dropout, L2)

TabNet / FT-Transformer (advanced)

Specifically designed for tabular data

Good interpretability + accuracy

More complex but useful if you have lots of strike, delta, or vega-based features

////////////





1. ARIMA (AutoRegressive Integrated Moving Average): Uses a Linear Regression as the base model. Captures autoregressive and moving average terms, along with integrating the differencing of raw observations (to make the time series stationary). Local only (requires loops for each time series). AutoARIMA is my preferred implementation.

2. Prophet: A forecasting tool developed by Facebook. Designed for data with daily observations and seasonal patterns, employing an additive model with yearly, weekly, and daily components. Local forecasting (requires loops).

3. LSTM (Long Short-Term Memory): A type of recurrent neural network (RNN) used in deep learning. It is specifically designed to avoid the long-term dependency problem, making it effective for time series. My preferred implementation is AWS's GluonTS DeepAR. 

4. Holt-Winters Method: A statistical forecasting technique that applies exponential smoothing to capture trend and seasonality in time series data. Useful for data with a clear trend and seasonal pattern. A special case of Exponential Smoothing. 

5. SARIMA (Seasonal ARIMA): An extension of ARIMA that incorporates seasonality. Designed for time series with both non-seasonal and seasonal components, making it more flexible than the standard ARIMA model. AutoARIMA is my preferred implementation.

6. Exponential Smoothing: Applies exponentially decreasing weights to past observations. Best for short-term forecasts, particularly effective for data without trends or seasonal patterns. ETS (Exponential-Trend-Smoothing) is my preferred implementation. 

7. Random Forest: An ensemble learning method that makes many decision trees. The forecast is the mean prediction of the individual trees. Global or local. Scalable. Cannot predict over max/min due to tree-based algorithm problem. 

8. XGBoost: An efficient and scalable implementation of gradient boosting. Known for its high performance and flexibility in handling various types of predictive modeling tasks. Does well at detecting complex seasonality provided feature engineering is performed. Global or local. Cannot predict over global min/max. 
